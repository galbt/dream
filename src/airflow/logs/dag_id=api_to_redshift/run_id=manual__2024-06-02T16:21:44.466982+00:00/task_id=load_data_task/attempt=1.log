[2024-06-02T16:21:54.390+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-06-02T16:21:54.404+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_to_redshift.load_data_task manual__2024-06-02T16:21:44.466982+00:00 [queued]>
[2024-06-02T16:21:54.409+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_to_redshift.load_data_task manual__2024-06-02T16:21:44.466982+00:00 [queued]>
[2024-06-02T16:21:54.410+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-06-02T16:21:54.418+0000] {taskinstance.py:2330} INFO - Executing <Task(BashOperator): load_data_task> on 2024-06-02 16:21:44.466982+00:00
[2024-06-02T16:21:54.424+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-06-02T16:21:54.426+0000] {standard_task_runner.py:63} INFO - Started process 85 to run task
[2024-06-02T16:21:54.426+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'api_to_redshift', 'load_data_task', 'manual__2024-06-02T16:21:44.466982+00:00', '--job-id', '310', '--raw', '--subdir', 'DAGS_FOLDER/get_data.py', '--cfg-path', '/tmp/tmptyrm3j2i']
[2024-06-02T16:21:54.428+0000] {standard_task_runner.py:91} INFO - Job 310: Subtask load_data_task
[2024-06-02T16:21:54.470+0000] {task_command.py:426} INFO - Running <TaskInstance: api_to_redshift.load_data_task manual__2024-06-02T16:21:44.466982+00:00 [running]> on host 3b1c84e3bc24
[2024-06-02T16:21:54.546+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='Data Team' AIRFLOW_CTX_DAG_ID='api_to_redshift' AIRFLOW_CTX_TASK_ID='load_data_task' AIRFLOW_CTX_EXECUTION_DATE='2024-06-02T16:21:44.466982+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-06-02T16:21:44.466982+00:00'
[2024-06-02T16:21:54.549+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-06-02T16:21:54.551+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2024-06-02T16:21:54.552+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', "curl 'http://s3-to-redshift-lambda:8080/2015-03-31/functions/function/invocations' -d '{}'"]
[2024-06-02T16:21:54.564+0000] {subprocess.py:86} INFO - Output:
[2024-06-02T16:21:54.575+0000] {subprocess.py:93} INFO -   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
[2024-06-02T16:21:54.576+0000] {subprocess.py:93} INFO -                                  Dload  Upload   Total   Spent    Left  Speed
[2024-06-02T16:21:55.147+0000] {subprocess.py:93} INFO -   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0{"errorMessage": "(psycopg2.OperationalError) connection to server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused\n\tIs the server running on that host and accepting TCP/IP connections?\nconnection to server at \"localhost\" (::1), port 5432 failed: Cannot assign requested address\n\tIs the server running on that host and accepting TCP/IP connections?\n\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "errorType": "OperationalError", "requestId": "890df478-2a8c-4bbc-bc08-6dd1bf610aaf", "stackTrace": ["  File \"/var/task/lambda_function.py\", line 49, in lambda_handler\n    status_code = data_to_redshift(df)\n", "  File \"/var/task/lambda_function.py\", line 42, in data_to_redshift\n    status_code = data.to_sql(table_name, engine, if_exists='replace', index=True)\n", "  File \"/var/lang/lib/python3.12/site-packages/pandas/util/_decorators.py\", line 333, in wrapper\n    return func(*args, **kwargs)\n", "  File \"/var/lang/lib/python3.12/site-packages/pandas/core/generic.py\", line 3087, in to_sql\n    return sql.to_sql(\n", "  File \"/var/lang/lib/python3.12/site-packages/pandas/io/sql.py\", line 841, in to_sql\n    with pandasSQL_builder(con, schema=schema, need_transaction=True) as pandas_sql:\n", "  File \"/var/lang/lib/python3.12/site-packages/pandas/io/sql.py\", line 906, in pandasSQL_builder\n    return SQLDatabase(con, schema, need_transaction)\n", "  File \"/var/lang/lib/python3.12/site-packages/pandas/io/sql.py\", line 1636, in __init__\n    con = self.exit_stack.enter_context(con.connect())\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 3276, in connect\n    return self._connection_cls(self)\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 148, in __init__\n    Connection._handle_dbapi_exception_noconnection(\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 2440, in _handle_dbapi_exception_noconnection\n    raise sqlalchemy_exception.with_traceback(exc_info[2]) from e\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 146, in __init__\n    self._dbapi_connection = engine.raw_connection()\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/engine/base.py\", line 3300, in raw_connection\n    return self.pool.connect()\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 449, in connect\n    return _ConnectionFairy._checkout(self)\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 1263, in _checkout\n    fairy = _ConnectionRecord.checkout(pool)\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 712, in checkout\n    rec = pool._do_get()\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 179, in _do_get\n    with util.safe_reraise():\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/impl.py\", line 177, in _do_get\n    return self._create_connection()\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 390, in _create_connection\n    return _ConnectionRecord(self)\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 674, in __init__\n    self.__connect()\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 900, in __connect\n    with util.safe_reraise():\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py\", line 146, in __exit__\n    raise exc_value.with_traceback(exc_tb)\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/pool/base.py\", line 896, in __connect\n    self.dbapi_connection = connection = pool._invoke_creator(self)\n", "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/engine/create.py\", line 643, in connect\n    return dialect.connect(*cargs, **cparams)\n"100  4437    0  4435  100     2   7754      3 --:--:-- --:--:-- --:--:--  7770
[2024-06-02T16:21:55.150+0000] {subprocess.py:93} INFO - , "  File \"/var/lang/lib/python3.12/site-packages/sqlalchemy/engine/default.py\", line 620, in connect\n    return self.loaded_dbapi.connect(*cargs, **cparams)\n", "  File \"/var/lang/lib/python3.12/site-packages/psycopg2/__init__.py\", line 122, in connect\n    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)\n"]}
[2024-06-02T16:21:55.151+0000] {subprocess.py:97} INFO - Command exited with return code 0
[2024-06-02T16:21:55.152+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-06-02T16:21:55.181+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=api_to_redshift, task_id=load_data_task, run_id=manual__2024-06-02T16:21:44.466982+00:00, execution_date=20240602T162144, start_date=20240602T162154, end_date=20240602T162155
[2024-06-02T16:21:55.209+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-06-02T16:21:55.226+0000] {taskinstance.py:3498} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-06-02T16:21:55.228+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
